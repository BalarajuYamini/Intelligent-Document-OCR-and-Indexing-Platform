{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-psaMGUS18F"
      },
      "outputs": [],
      "source": [
        "#  Install necessary packages\n",
        "!pip install -q google-generativeai python-magic\n",
        "!sudo apt-get install -y libmagic1\n",
        "!pip install openpyxl\n",
        "!pip install PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubR1K_c5TMCv"
      },
      "outputs": [],
      "source": [
        "# Set your API Key securely\n",
        "import os\n",
        "\n",
        "# Replace this with your actual Gemini API key from https://makersuite.google.com/app/apikey\n",
        "GOOGLE_API_KEY = \"enter your api\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1i_hUXF-TWxE"
      },
      "outputs": [],
      "source": [
        "# Authenticate with Gemini and import required libraries\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import content_types\n",
        "import mimetypes\n",
        "from pathlib import Path\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# Load Gemini Pro Vision (multimodal model for OCR)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro-vision\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFCo2CyHTYLB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import mimetypes\n",
        "import google.generativeai as genai\n",
        "import time # For checking file upload status\n",
        "\n",
        "# Configure your Gemini API key (replace with your actual API key or environment variable)\n",
        "# genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "#  Upload your document file (PDF, JPG, PNG, etc.)\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded))\n",
        "file_path = Path(file_name)\n",
        "\n",
        "#  Determine MIME type\n",
        "mime_type, _ = mimetypes.guess_type(file_path)\n",
        "\n",
        "# Upload the file to Gemini and get its URI\n",
        "print(f\"Uploading {file_name} as {mime_type}...\")\n",
        "try:\n",
        "    # Use a unique name for the file to avoid conflicts\n",
        "    # For example, appending a timestamp: f\"{file_path.stem}-{int(time.time())}{file_path.suffix}\"\n",
        "    uploaded_file = genai.upload_file(\n",
        "        path=str(file_path),\n",
        "        display_name=f\"{file_path.stem}_uploaded\", # A human-readable name\n",
        "        mime_type=mime_type\n",
        "    )\n",
        "    print(f\"File uploaded: {uploaded_file.uri}\")\n",
        "\n",
        "    # Wait for the file to be processed\n",
        "    while uploaded_file.state.name == \"PROCESSING\":\n",
        "        print(\"Waiting for file to be processed...\", end=\"\")\n",
        "        time.sleep(5)\n",
        "        uploaded_file = genai.get_file(uploaded_file.name)\n",
        "\n",
        "    if uploaded_file.state.name == \"FAILED\":\n",
        "        raise ValueError(f\"File processing failed: {uploaded_file.state.name}\")\n",
        "\n",
        "    # Now you can use the uploaded_file.uri in your prompt\n",
        "    file_part = uploaded_file # The uploaded_file object can be directly used as a Part in the prompt\n",
        "    print(\"File ready for use in prompt.\")\n",
        "\n",
        "    # Example of how to use it in a prompt:\n",
        "    # model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "    # response = model.generate_content([file_part, \"What is in this document?\"])\n",
        "    # print(response.text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during file upload or processing: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMIsUvB5TmYR"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "# Assuming uploaded_file is available from the previous successful upload code\n",
        "\n",
        "# 1. Initialize the Gemini Model\n",
        "# Choose an appropriate model that supports multimodal input\n",
        "# 'gemini-1.5-flash-latest' is generally good for speed and cost-effectiveness\n",
        "# 'gemini-1.5-pro-latest' offers more advanced reasoning\n",
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# 2. Construct Your Prompt\n",
        "# Your prompt can be a mix of text and the uploaded file.\n",
        "# The uploaded_file object from genai.upload_file can be directly included.\n",
        "prompt_parts = [\n",
        "    uploaded_file, # This is the object referencing your uploaded file\n",
        "    \"What is this document about? Summarize its key points in bullet points.\"\n",
        "    # You can customize your prompt based on the file type:\n",
        "    # For an image: \"Describe this image in detail.\"\n",
        "    # For a PDF: \"Extract the main headings and their content from this PDF.\"\n",
        "    # For a video: \"What are the main events in this video and at what timestamps?\"\n",
        "]\n",
        "\n",
        "# 3. Generate Content\n",
        "print(\"\\nGenerating content with the Gemini model...\")\n",
        "try:\n",
        "    response = model.generate_content(prompt_parts)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\n--- Gemini's Response ---\")\n",
        "    print(response.text)\n",
        "\n",
        "    # You can also access other attributes of the response, like safety ratings, etc.\n",
        "    # print(\"\\n--- Safety Ratings ---\")\n",
        "    # for rating in response.prompt_feedback.safety_ratings:\n",
        "    #     print(f\"Category: {rating.category.name}, Probability: {rating.probability.name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during content generation: {e}\")\n",
        "\n",
        "# Optional: Clean up the uploaded file if you no longer need it\n",
        "# Files uploaded via genai.upload_file are automatically deleted after 48 hours,\n",
        "# but you can delete them manually if you're done with them immediately.\n",
        "# print(f\"\\nDeleting uploaded file: {uploaded_file.display_name}...\")\n",
        "# genai.delete_file(uploaded_file.name)\n",
        "# print(\"File deleted.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HjN2sQYrk-iX"
      },
      "outputs": [],
      "source": [
        "#  Function to Extract Text from PDF\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    doc = fitz.open(file_path)\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QY4yWQKXovKy"
      },
      "outputs": [],
      "source": [
        "def generate_summary_with_gemini(text):\n",
        "    print(\" Generating summary using dummy Gemini\")\n",
        "    return \"Summary: \" + text[:1000] + \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9y9pycPoOG2"
      },
      "outputs": [],
      "source": [
        "#  Full Process Execution\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Gemini Summary Function (moved outside try block and properly indented)\n",
        "def generate_summary_with_gemini(text):\n",
        "    if not text.strip():\n",
        "        return \"No text extracted from document to summarize.\"\n",
        "    try:\n",
        "        print(\" Generating summary from Gemini...\")\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        prompt = [\n",
        "            text[:3000],  # Truncate if needed\n",
        "            \"Please summarize the key points of this document in bullet points.\"\n",
        "        ]\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error from Gemini: {e}\"\n",
        "\n",
        "#  Extract → Summarize → Store in Table\n",
        "try:\n",
        "    extracted_text = extract_text_from_pdf(file_path)\n",
        "    summary = generate_summary_with_gemini(extracted_text)\n",
        "    upload_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    data = {\n",
        "        \"File Name\": [file_path.name],\n",
        "        \"Upload Time\": [upload_time],\n",
        "        \"Extracted Text (first 1000 chars)\": [extracted_text[:1000]],\n",
        "        \"Gemini Summary\": [summary]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\" Final Table:\")\n",
        "    display(df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\" Error occurred:\", str(e))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
